# Facial Landmark Localization with Recurrent Cascading CNNs

## Project description

Facial landmark localization (FLL) is an important computer vision problem involving the regressing of keypoints from a face in an image. This task is difficult due to the wide variety of facial expressions, pose variations, and keypoint occlusion by angle, lighting, and obstructions such as glasses and hair. Previous methods involved fitting a model to lower-dimensional representations of the face, while today, convolutional nueral networks are a major focus of research in this area. In particular, cascading CNNs, which involve chaining CNN modules with correlated tasks, such as constructing a featurized representation of the face, mapping a heatmap to possible keypoint locations, and regressing the keypoints themselves, are shown to be promisingly capable. In this project, I plan to adapt successful Cascading CNN models from the literature with a focus on reducing parameters and increasing robustness to variant poses with incorporation of self-attention (SA) mechanisms. I beleive SA in the form of convolutional self-attention and spatial transformers will yield a model that can map long-range dependencies in  images more effectively (an important aspect of heatmap construction), while increasing its accuracy on otherwise-tricky poses and expressions.

## The Model

My model is a fusion of the ideas of (1) and (2) featuring a recurrent cascading CNN (RCCNN) scheme that has been shown to increase the accuracy of heatmap and regression predictions on each pass. Loss is assessed after each recurrent estimationto assist with backpropagation<br><br>

<img src="./readme_materials/network.png">

## Training Objective

The regression module were trained to minimize the mean squared error between their predictions and the true landmark locations, while the heatmap module minimized the cross-entropy between their predicted probabilistic heatmap and a target generated by placing a bivariate gaussian with standard-deviation of 2.5 pixels on each landmark.

## Input Pipeline

Pre-processing for images fed into the network required careful execution, as raw images from the HELEN dataset used for training had often had multiple faces in the frame, faces off-center, and widely varying image sizes. Furthermore, common data augmentations such as zoom, cropping, and rotation affect the image content as well as the location of the landmarks, so positional augmentations made must be made to both. The HELEN dataset contains 2300 images, which is unlikely to train a generalizable model for this complex localization function, so these augmentations are a must. 

In order to facilitate these augmentations, I first created a new dataset in which the maximum image size was reduced to approximately 750 x 750 pixels to reduce read-time, then these images were piped through the following steps to produce stochastic close-crops of subjects' faces:



## Future Directions



## References

1. <a href="https://arxiv.org/pdf/1805.01760.pdf">Facial Landmark Point Localization using Coarse-to-Fine Deep Recurrent Neural Network"</a>
2. <a href="https://arxiv.org/abs/1605.02914">Recurrent Human Pose Estimation</a>
